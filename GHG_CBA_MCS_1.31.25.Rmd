---
title: Monte Carlo Simulation for GHG Measure CBA
author: Brandon
project: Dissertation chapter 3
date: Jan 31, 2025
---

TO-DO:
1. Add description here. Boundary acts like a single functional unit. Each parameter is a single functional unit with multiple GHG, non-GHG, and cost factors.

2. Consider how to deal with scope 3 EFs. Electricity for example, has upstream factors. Combine into one electricity EF? Or keep separate for in/out of jurisdiction reporting? 

3. add costs to excel export. Think about how to export discounted costs

4. Turn each MCS loop into a function. A different function for the different PDF types

Package Install & Load
```{r setup}
if (!require("dplyr")) install.packages("dplyr")
library(dplyr)
if (!require("readxl")) install.packages("readxl")
library(readxl)
if (!require("writexl")) install.packages("writexl")
library(writexl)
if (!require("ggplot2")) install.packages("ggplot2")
library(ggplot2)
if (!require("scales")) install.packages("scales")
library(scales)
if (!require("data.table")) install.packages("data.table")
library(data.table)
```


```{r}
# Define the following global variables to be called by parameter functions

run_count <- 1000
scenario_start <- 2025
scenario_end  <- 2050
year_count <- scenario_end - scenario_start + 1
```

Create CO2e Emission Factor Library
```{r}
EFLco2e("ar6")
write_xlsx(EFL, path = "EFLco2e.xlsx")
```



Emission Factor Simulations
```{r}

# Specify file path
efs <- "emission_factors.xlsx"

# Get the names of all sheets in the Excel file
ef_names <- excel_sheets(efs)

# Read each sheet into a list of dataframes, named after the sheet names
ef_data <- lapply(ef_names, function(sheet) {
  read_excel(efs, sheet = sheet)
})

# Assign names to the list elements
names(ef_data) <- ef_names

# Assign each sheet as a separate dataframe in your environment
list2env(ef_data, envir = .GlobalEnv)

# Create empty data frames for Monte Carlo outputs
electricity_combustion_out <- electricity_combustion[0,]
electricity_upstream_out <- electricity_upstream[0,]
natural_gas_out <- natural_gas[0,]

# Run a for loop to randomly select a row from each dataframe
for (i in 1:run_count) {
  random_row <- electricity_combustion %>%
    slice_sample(n = 1) 
  electricity_combustion_out <- rbind(electricity_combustion_out, random_row)
}

for (i in 1:run_count) {
  random_row <- electricity_upstream %>%
    slice_sample(n = 1) 
  electricity_upstream_out <- rbind(electricity_upstream_out, random_row)
}

for (i in 1:run_count) {
  random_row <- natural_gas %>%
    slice_sample(n = 1) 
  natural_gas_out <- rbind(natural_gas_out, random_row)
}

```

Parameter 1 Boundary Simulations
```{r}

# Get the names of all sheets in the Excel file
boundary_names <- excel_sheets("p1/boundary.xlsx")

# Read each sheet into a list of dataframes, named after the sheet names
boundary_data <- lapply(boundary_names, function(sheet) {
  read_excel("p1/boundary.xlsx", sheet = sheet)
})

# Assign names to the list elements
names(boundary_data) <- boundary_names

# Assign each sheet as a separate dataframe in your environment
list2env(boundary_data, envir = .GlobalEnv)

# Create empty data frames for Monte Carlo outputs
ref_boundary_out <- ref_boundary[0,]
intv_boundary_out <- intv_boundary[0,]

# Run a for loop to randomly select a row for the reference boundary
for (i in 1:run_count) {
  random_row <- ref_boundary %>%
    slice_sample(n = 1) 
  ref_boundary_out <- rbind(ref_boundary_out, random_row)
}

# Run a for loop to randomly select a value for the intervention boundary
for (i in 1:run_count) {
  random_value <- sample(18:21, size = 1)
  pdf_out <- as.data.frame(rbind(c(intv_boundary[1,1:3],rep(random_value, times = 11),rep(0, times = 15))))
  colnames(pdf_out) <- colnames(intv_boundary_out)
  pdf_out[,4:29] <- lapply(pdf_out[,4:29], as.numeric)
  intv_boundary_out <- rbind(intv_boundary_out, pdf_out)
}

# Make sure no columns are stores as lists
intv_boundary_out[] <- lapply(intv_boundary_out, function(x) if (is.list(x)) unlist(x) else x)

# Transform boundary data from annual totals to cumulative totals

ref_boundary_cumsum <- as.data.frame(t(apply(ref_boundary_out[,4:29], 1, cumsum))) # cumulative reference boundary.
intv_boundary_cumsum <- as.data.frame(t(apply(intv_boundary_out[,4:29], 1, cumsum))) # cumulative intervention boundary
net_boundary_cumsum <- intv_boundary_cumsum-ref_boundary_cumsum # net cumulative boundary

```

Parameter 1 Factor Simulations
```{r}

# Get the names of all sheets in the Excel file
factor_names <- excel_sheets("p1/factors.xlsx")

# Read each sheet into a list of dataframes, named after the sheet names
factor_data <- lapply(factor_names, function(sheet) {
read_excel("p1/factors.xlsx", sheet = sheet)
})
  
# Assign names to the list elements
names(factor_data) <- factor_names

# Assign each sheet as a separate dataframe in your environment
list2env(factor_data, envir = .GlobalEnv)

# Create empty data frames for Monte Carlo outputs
ref_factor1_out <- ref_factor1[0,] # electricity
ref_factor2_out <- ref_factor2[0,] # natural gas
intv_factor_out <- intv_factor[0,] # % energy savings

# Run a for loop to randomly select a row for ref_factor1
for (i in 1:run_count) {
  random_row <- ref_factor1 %>%
    slice_sample(n = 1)  
   ref_factor1_out <- rbind(ref_factor1_out, random_row)
}

# Run a for loop to randomly select a row for ref_factor2
for (i in 1:run_count) {
  random_row <- ref_factor2 %>%
    slice_sample(n = 1)  
   ref_factor2_out <- rbind(ref_factor2_out, random_row)   
}

# Run a for loop to randomly select a value for intv_factor
for (i in 1:run_count) {
  random_value <- rnorm(1, mean = .3, sd = .03)
  pdf_out <- as.data.frame(rbind(c(intv_factor[1,1:3],rep(random_value, times = 26))))
  colnames(pdf_out) <- colnames(intv_factor_out)
  pdf_out[,4:29] <- lapply(pdf_out[,4:29], as.numeric)
  intv_factor_out <- rbind(intv_factor_out, pdf_out)
}
# Make sure no columns are stores as lists
intv_factor_out[] <- lapply(intv_factor_out, function(x) if (is.list(x)) unlist(x) else x)


# Process reference factor 1 (electricity, kWh)

ref_values1 <- net_boundary_cumsum*ref_factor1_out[4:29]
ref_data1 <- cbind(ref_factor1_out[,1:3],ref_values1)
ref_data1$unit_b <- NA

# Process reference factor 2 (natural gas, therms)

ref_values2 <- net_boundary_cumsum*ref_factor2_out[4:29]
ref_data2 <- cbind(ref_factor2_out[,1:3],ref_values2)
ref_data2$unit_b <- NA

# Calculate mitigation factor for the intervention scenario. Applies globally to each reference factor

mitigation_values <- intv_factor_out[4:29]
mitigation_values[] <- data.frame(lapply(mitigation_values, as.numeric))
intv_mitigation_factor <- 1 - mitigation_values

# Process intervention factor 1

intv_values1 <- ref_values1*intv_mitigation_factor
intv_data1 <- cbind(ref_data1[,1:3],intv_values1)
intv_data1$scenario_type <- "intervention scenario"
intv_data1$unit_b <- NA

# Process intervention factor 2

intv_values2 <- ref_values2*intv_mitigation_factor
intv_data2 <- cbind(ref_data2[,1:3],intv_values2)
intv_data2$scenario_type <- "intervention scenario"
intv_data2$unit_b <- NA

```

Parameter 1 Cost Simulations
```{r}

# Get the names of all sheets in the Excel file
cost_names <- excel_sheets("p1/costs.xlsx")

# Read each sheet into a list of dataframes, named after the sheet names
cost_data <- lapply(cost_names, function(sheet) {
  read_excel("p1/costs.xlsx", sheet = sheet)
})

# Assign names to the list elements
names(cost_data) <- cost_names

# Assign each sheet as a separate dataframe in your environment
list2env(cost_data, envir = .GlobalEnv)

# Create empty data frames for Monte Carlo outputs
ref_capex1_out <- ref_capex1[0,]
ref_opex1_out <- ref_opex1[0,]
ref_opex2_out <- ref_opex2[0,]
intv_capex1_out <- intv_capex1[0,]
intv_opex1_out <- intv_opex1[0,]
intv_opex2_out <- intv_opex2[0,]

# Run a for loop to randomly select a row for ref_capex1
for (i in 1:run_count) {
  random_row <- ref_capex1 %>%
    slice_sample(n = 1)  
   ref_capex1_out <- rbind(ref_capex1_out, random_row)
}
 
# Run a for loop to randomly select a row for ref_opex1
for (i in 1:run_count) {
  random_row <- ref_opex1 %>%
    slice_sample(n = 1)  
   ref_opex1_out <- rbind(ref_opex1_out, random_row)  
}

# Run a for loop to randomly select a row for ref_opex2
for (i in 1:run_count) {
  random_row <- ref_opex2 %>%
    slice_sample(n = 1)  
   ref_opex2_out <- rbind(ref_opex2_out, random_row)  
}

# Run a for loop to randomly select a value for intv_capex1
for (i in 1:run_count) {
  random_value <- rnorm(1, mean = -5117, sd = 52)
  pdf_out <- as.data.frame(rbind(c(intv_capex1[1,1:3],rep(random_value, times = 26))))
  colnames(pdf_out) <- colnames(intv_capex1_out)
  pdf_out[,4:29] <- lapply(pdf_out[,4:29], as.numeric)
  intv_capex1_out <- rbind(intv_capex1_out, pdf_out)
}
# Make sure no columns are stores as lists
intv_capex1_out[] <- lapply(intv_capex1_out, function(x) if (is.list(x)) unlist(x) else x)

# Run a for loop to randomly select a row for intv_opex1
for (i in 1:run_count) {
  random_row <- intv_opex1 %>%
    slice_sample(n = 1)  
   intv_opex1_out <- rbind(intv_opex1_out, random_row)  
}

# Run a for loop to randomly select a row for intv_opex2
for (i in 1:run_count) {
  random_row <- intv_opex2 %>%
    slice_sample(n = 1)  
   intv_opex2_out <- rbind(intv_opex2_out, random_row) 
}

# calculate reference costs
ref_capex1_costcalc <- ref_boundary_out[,4:29]*ref_capex1_out[,4:29]
ref_opex1_costcalc <- net_boundary_cumsum*ref_factor1_out[,4:29]*ref_opex1_out[,4:29]
ref_opex2_costcalc <- net_boundary_cumsum*ref_factor2_out[,4:29]*ref_opex2_out[,4:29]

# calculate intervention costs
intv_capex1_costcalc <- intv_boundary_out[,4:29]*intv_capex1_out[,4:29]
intv_opex1_costcalc <- net_boundary_cumsum*ref_factor1_out[,4:29]*intv_opex1_out[,4:29]*intv_mitigation_factor
intv_opex2_costcalc <- net_boundary_cumsum*ref_factor2_out[,4:29]*intv_opex2_out[,4:29]*intv_mitigation_factor

# Consolidate total costs
ref_costcalc <- (ref_capex1_costcalc + ref_opex1_costcalc + ref_opex2_costcalc)
intv_costcalc <- (intv_capex1_costcalc + intv_opex1_costcalc + intv_opex2_costcalc)

cashflow_econ <- intv_costcalc - ref_costcalc
cashflow_private <- intv_capex1_costcalc - ref_capex1_costcalc

```

Parameter 1 GHG Calculations
```{r}
# calculate GHG emissions for reference factor 1

ef1 <- electricity_combustion_out # Scope 2 electricity emission factors
ref_ghgcalc1 <- ref_data1[,4:29]*ef1[10:35]/1000 
ref_ghg1 <- cbind(ref_data1[,1],ef1[1:5],ref_ghgcalc1)
colnames(ref_ghg1)[7] <- "unit"
ref_ghg1$unit <- "mtco2e"

# calculate GHG emissions for reference factor 2

ef2 <- natural_gas_out # Scope 1 natural gas emission factors
ref_ghgcalc2 <- ref_data2[,4:29]*ef2[10:35]/1000
ref_ghg2 <- cbind(ref_data2[,1],ef2[1:5],ref_ghgcalc2)
colnames(ref_ghg2)[7] <- "unit"
ref_ghg2$unit <- "mtco2e"

# calculate total reference GHG emissions

ref_ghgtotal <- ref_ghgcalc1 + ref_ghgcalc2

# calculate GHG emissions for intervention factor 1

intv_ghgcalc1 <- intv_data1[,4:29]*electricity_combustion_out[10:35]/1000 # Scope 2 electricity emission factors
intv_ghg1 <- cbind(intv_data1[,1],ef1[1:5],intv_ghgcalc1)
colnames(intv_ghg1)[7] <- "unit"
intv_ghg1$unit <- "mtco2e"

# calculate GHG emissions for intervention factor 2

intv_ghgcalc2 <- intv_data2[,4:29]*natural_gas_out[10:35]/1000 # Scope 1 natural gas emission factors
intv_ghg2 <- cbind(intv_data2[,1],ef2[1:5],intv_ghgcalc2)
colnames(intv_ghg2)[7] <- "unit"
intv_ghg2$unit <- "mtco2e"

# calculate total intervention GHG emissions

intv_ghgtotal <- intv_ghgcalc1 + intv_ghgcalc2

# Calculate GHG mitigation

ghg_mitigation <- ref_ghgtotal - intv_ghgtotal
p1_ghg_mitigation <- ghg_mitigation
```


Parameter 1 Co-benefits 
```{r}
# Get the names of all sheets in the Excel file
factor_names <- excel_sheets("p1/cobenefits.xlsx")

# Read each sheet into a list of dataframes, named after the sheet names
factor_data <- lapply(factor_names, function(sheet) {
read_excel("p1/cobenefits.xlsx", sheet = sheet)
})
  
# Assign names to the list elements
names(factor_data) <- factor_names

# Assign each sheet as a separate dataframe in your environment
list2env(factor_data, envir = .GlobalEnv)

# Create empty data frames for Monte Carlo outputs
coben1_out <- coben1[0,] # social cost of carbon

# Run a for loop to simulate the SCC
for (i in 1:run_count) {
  random_value <- rnorm(1, mean = 44, sd = 37)
  growth_rate <- 1.03
  SCC <- random_value * (growth_rate)^(0:25)
  pdf_out <- as.data.frame(rbind(c(coben1[1,1:3],SCC)))
  colnames(pdf_out) <- colnames(coben1_out)
  pdf_out[,4:29] <- lapply(pdf_out[,4:29], as.numeric)
  coben1_out <- rbind(coben1_out, pdf_out)
}
# Make sure no columns are stores as lists
coben1_out[] <- lapply(coben1_out, function(x) if (is.list(x)) unlist(x) else x)

# Calculate social value from Parameter 1 co-benefits 

coben1_value <- ghg_mitigation * coben1_out[,4:29]
coben1_value <- cbind(coben1_out[,1:3],coben1_value)
coben1_value$coben_name <- "Social value of GHG mitigation (in 2025 USD)"
coben1_value$unit_b <- NA
cobenefit_value <- coben1_value[,4:29]

```

Parameter 1 output
```{r}
#NEED TO FIX - maybe split into multiple outputs 

p1_outputlist <- (list("ref_boundary_out" = ref_boundary_out,
                    "intv_boundary_out" = intv_boundary_out, 
                    "ref_factor1_out" = ref_factor1_out,
                    "ref_factor2_out" = ref_factor2_out,
                    "intv_factor_out" = intv_factor_out,
                    "ref_capex1_out" = ref_capex1_out,
                    "intv_capex1_out" = intv_capex1_out,
                    "ref_opex1_out" = ref_opex1_out,
                    "intv_opex1_out" = intv_opex1_out,
                    "ref_opex2_out" = ref_opex2_out,
                    "intv_opex2_out" = intv_opex2_out,
                    "ref_data1" = ref_data1,
                    "intv_data1" = intv_data1,
                    "ref_data2" = ref_data2,
                    "intv_data2" = intv_data2,
                    "emission_factors_1" = ef1,
                    "emission_factors_2" = ef2,
                    "ref_ghg1" = ref_ghg1,
                    "intv_ghg1" = intv_ghg1,
                    "ref_ghg2" = ref_ghg2,
                    "intv_ghg2" = intv_ghg2,
                    "ref_ghgtotal" = ref_ghgtotal,
                    "intv_ghgtotal" = intv_ghgtotal,
                    "net_ghg" = ghg_mitigation,
                    "scc" = coben1_out,
                    "social_value" = coben1_value))

#write excel and save p1 outputs (NOTE: Change names for each parameter)

write_xlsx(p1_outputlist, path = "p1_output.xlsx")

```

Disocunt Rate Matrix: NPV Calcs
```{r}
years <- 2025:2050
scenario_lifetime <- 16 # select scenario lifetime (start = 2025). max value is 26
npv_econ_dr <- data.frame(matrix(NA, nrow = run_count, ncol = 71)) # make an empty matrix to populate NPV for each discount rate
colnames(npv_econ_dr) <- ((0:70)/10) # column headers for each discount rate: seq(0, 7, by = 0.1)

for (i in 0:70) { # the loop repeats for each discount rate seq(0, 7, by = 0.1)
  drvalues <- numeric(26) # an empty vector 'drvalues' is created to house the loop outputs
  drvalues[1] <- 1        
    for (n in 2:26) {
         drvalues[n] <- (1+(i/1000))^(n-1) # drvalues is populated with the discount rate conversion factor for each year
    }
  drvalues_df <- data.frame(t(drvalues)) # make a dataframe out of the discount rate loop output
  colnames(drvalues_df) <- years # make the column headers years
  discount_df <- drvalues_df[rep(1, run_count),] # the discount rate vector is replicated into rows equal to the MCS run count
  annual_npv <- cashflow_econ/discount_df # the total annual economic cash flow is converted into NPV
  annual_npv_cumsum <- as.data.frame(t(apply(annual_npv, 1, cumsum))) # net present value is summed cumulatively for each year
  npv <- annual_npv_cumsum[scenario_lifetime] # the total NPV is selected based on the scenario lifetime
  col_rename <- i/10 #rename column with the discount rate
  colnames(npv) <- col_rename
  npv_econ_dr[,i+1] <- npv #bind the NPV values for each MCS row for the given discount rate
}

# Create vector for cumulative co-benefit value 
coben_value_sum <- rowSums(cobenefit_value[,4:scenario_lifetime])

# Add the social value to each column in the economic npv dataframe
npv_social_dr <- data.frame(matrix(nrow = nrow(npv_econ_dr), ncol = ncol(npv_econ_dr)))
colnames(npv_social_dr) <- ((0:70)/10)
for (i in seq_along(npv_econ_dr)) {
   npv_social_dr[[i]] <-  npv_econ_dr[[i]] + coben_value_sum
}

```

LCCA Calcs
```{r}
# Cumulative sum of GHG mitigation

ghg_cumsum_annual <- as.data.frame(t(apply(p1_ghg_mitigation, 1, cumsum)))
ghg_cumsum <- ghg_cumsum_annual[scenario_lifetime]
ghg_dr <- data.frame(matrix(rep(ghg_cumsum[,1], 71), ncol = 71))

# Calculate economic LCCA for each discount rate
lcca_econ_dr <- (npv_econ_dr * -1)/ghg_dr

# Calculate social LCCA for each discount rate
lcca_social_dr <- (npv_social_dr * -1)/ghg_dr


```

LCCA: Calculate Median and Quantiles
```{r}

# Stats for economic LCCA
lcca_econ_stats <- data.frame(
  Year = character(),
  Median = numeric(),
  Lower = numeric(),
  Upper = numeric(),
  stringsAsFactors = FALSE
)

for (i in 1:71) {
  # Extract the values for each discount rate
  values <- lcca_econ_dr[,i]
  
  # Calculate statistics
  median <- median(values)        
  lower_bound <- quantile(values, probs = 0.25)
  upper_bound <- quantile(values, probs = 0.75)
  
  # Append results to the results dataframe
  lcca_econ_stats <- rbind(
    lcca_econ_stats,
    data.frame(
      DR = colnames(lcca_econ_dr)[i],
      Median = median,
      Lower = lower_bound,
      Upper = upper_bound
    )
  )
}

# Stats for social LCCA
lcca_social_stats <- data.frame(
  Year = character(),
  Median = numeric(),
  Lower = numeric(),
  Upper = numeric(),
  stringsAsFactors = FALSE
)

for (i in 1:71) {
  # Extract the values for each discoutn rate
  values <- lcca_social_dr[,i]
  
  # Calculate statistics
  median <- median(values)        
  lower_bound <- quantile(values, probs = 0.25)
  upper_bound <- quantile(values, probs = 0.75)
  
  # Append results to the results dataframe
  lcca_social_stats <- rbind(
    lcca_social_stats,
    data.frame(
      DR = colnames(lcca_social_dr)[i],
      Median = median,
      Lower = lower_bound,
      Upper = upper_bound
    )
  )
}

```

NPV: Calculate Median and Quantiles
```{r}

# Stats for economic npv
npv_econ_stats <- data.frame(
  Year = character(),
  Median = numeric(),
  Lower = numeric(),
  Upper = numeric(),
  stringsAsFactors = FALSE
)

for (i in 1:71) {
  # Extract the values for each discount rate
  values <- npv_econ_dr[,i]
  
  # Calculate statistics
  median <- median(values)        
  lower_bound <- quantile(values, probs = 0.25)
  upper_bound <- quantile(values, probs = 0.75)
  
  # Append results to the results dataframe
  npv_econ_stats <- rbind(
    npv_econ_stats,
    data.frame(
      DR = colnames(npv_econ_dr)[i],
      Median = median,
      Lower = lower_bound,
      Upper = upper_bound
    )
  )
}

# Stats for social npv
npv_social_stats <- data.frame(
  Year = character(),
  Median = numeric(),
  Lower = numeric(),
  Upper = numeric(),
  stringsAsFactors = FALSE
)

for (i in 1:71) {
  # Extract the values for each discoutn rate
  values <- npv_social_dr[,i]
  
  # Calculate statistics
  median <- median(values)        
  lower_bound <- quantile(values, probs = 0.25)
  upper_bound <- quantile(values, probs = 0.75)
  
  # Append results to the results dataframe
  npv_social_stats <- rbind(
    npv_social_stats,
    data.frame(
      DR = colnames(npv_social_dr)[i],
      Median = median,
      Lower = lower_bound,
      Upper = upper_bound
    )
  )
}

```

NPV Matrix
```{r}
# Econ NPV matrix
npv_econ_medians <- data.frame(matrix(NA, nrow = 26, ncol = 71)) 
drcolnames <- paste0("dr",((0:70)/10))
colnames(npv_econ_medians) <- drcolnames # column headers for each discount rate: seq(0, 7, by = 0.1)
rownames(npv_econ_medians) <- years

# Social NPV matrix
npv_social_medians <- data.frame(matrix(NA, nrow = 26, ncol = 71)) 
colnames(npv_social_medians) <- drcolnames # column headers for each discount rate: seq(0, 7, by = 0.1)
rownames(npv_social_medians) <- years

# Create a cumulative sum of co-benefit value 
coben_cumsum <- as.data.frame(t(apply(cobenefit_value, 1, cumsum)))
median_coben_value <- data.frame(t(apply(coben_cumsum, 2, median))) # The median cumulative NPV value for each year is taken
median_coben_value_vector <- as.vector(unlist(median_coben_value))

for (i in 0:70) { # the loop repeats for each discount rate seq(0, 7, by = 0.1)
  drvalues <- numeric(26) # an empty vector 'drvalues' is created to house the loop outputs
  drvalues[1] <- 1        
    for (n in 2:26) {
         drvalues[n] <- (1+(i/1000))^(n-1) # drvalues is populated with the discount rate conversion factor for each year
    }
  drvalues_df <- data.frame(t(drvalues)) # make a dataframe out of the discount rate loop output
  discount_df <- drvalues_df[rep(1, run_count),] # the discount rate vector is replicated into rows equal to the MCS run count
  annual_npv_econ <- cashflow_econ/discount_df # the total annual economic cash flow is converted into NPV
  annual_npv_econ_cumsum <- as.data.frame(t(apply(annual_npv_econ, 1, cumsum))) # npv is summed cumulatively for each year
  median_npv_econ <- data.frame(t(apply(annual_npv_econ_cumsum, 2, median))) # median cumulative NPV value is taken for each year
  median_npv_vector <- as.vector(unlist(median_npv_econ))
  median_npv_social <- median_npv_vector + median_coben_value_vector# calculate the social npv
  npv_econ_medians[,i+1] <- median_npv_vector #bind the economic NPV values for the given discount rate
  npv_social_medians[,i+1] <- median_npv_social #bind the NPV social values for the given discount rate
}

```

Plot: Annual GHG Mitigation
```{r}

median_mitigation <- as.data.frame(t(apply(p1_ghg_mitigation, 2, median)))
cumulative_mitigation <- as.data.frame(t(apply(median_mitigation, 1, cumsum)))
mitigation_plot_data <- data.frame(
  Year1 = 2025:2050,
  Annual1 = unlist(median_mitigation[1,]),
  Cumulative1 = unlist(cumulative_mitigation[1,])
)

# Create the chart with a legend for cumulative and annual data
ggplot(mitigation_plot_data, aes(x = Year1)) +
  # Bar chart for cumulative data
  geom_bar(aes(y = Cumulative1, fill = "Cumulative Mitigation"), 
           stat = "identity", color = "black", width = 0.4, alpha = 0.7) +
  # Line chart for annual data
  geom_line(aes(y = Annual1 / max(Annual1) * max(Cumulative1), linetype = "Annual Mitigation"), 
            color = "black", linewidth = 1) +
  # Scale the primary y-axis and format with commas
  scale_y_continuous(
    name = "Cumulative GHG Reductions (mtco2e)",
    labels = label_comma(),  # Apply comma formatting to primary y-axis
    #breaks = seq(0, max(mitigation_plot_data$Cumulative1), by = 100),  # Adjust the 'by' parameter to control spacing
    sec.axis = sec_axis(
      ~ . * max(mitigation_plot_data$Annual1) / max(mitigation_plot_data$Cumulative1),
      name = "Annual GHG Reductions (mtco2e)",
      labels = label_comma()  # Apply comma formatting to secondary y-axis
    )
  ) +
  # Customize labels and theme
  labs(
    title = "Estimate of GHG Mitigation",
    x = "Year"
  ) +
  scale_fill_manual(values = c("Cumulative Mitigation" = "green4")) +  # Color for cumulative bars
  scale_linetype_manual(values = c("Annual Mitigation" = "dashed")) +  # Line style for annual data
  theme_minimal() +
  theme(
    legend.position = "bottom",  # Position the legend at the top
    legend.title = element_blank()  # Remove the legend title (Data Type)
  ) +
  guides(
    fill = guide_legend(title = NULL),  # Remove the legend title for fill (bars)
    linetype = guide_legend(title = NULL)  # Remove the legend title for linetype (line)
    )
```

Plot: NPV Histograms
```{r}
# Histogram of Economic NPV with 3% discount rate
npv_econ <- as.data.frame(npv_econ_dr[,30])
npv_econ_median <- npv_econ_stats[31,2]
npv_econ_lb <- npv_econ_stats[31,3]
npv_econ_ub <- npv_econ_stats[31,4]

ggplot(npv_econ, aes(x = npv_econ[,1])) +
  geom_histogram(binwidth = 20000, fill = "darkgrey", color = "black", alpha = 0.7) +
  geom_vline(aes(xintercept = npv_econ_median), color = "red", linetype = "dashed", size = 1) +  # median line
  geom_vline(aes(xintercept = npv_econ_lb), color = "green", linetype = "dotted", size = 1) +  # lower bound
  geom_vline(aes(xintercept = npv_econ_ub), color = "green", linetype = "dotted", size = 1) +  # upper bound
  labs(title = "Histogram of Economic NPV, with median and 25-75% percentiles", x = "npv", y = "Frequency") +
  scale_x_continuous(breaks = seq(-1000000, 1000000, by = 100000), labels = scales::comma) # need to adjust scales manually

# Histogram of Social NPV with 3% discount rate
npv_social <- as.data.frame(npv_social_dr[,30])
npv_social_median <- npv_social_stats[31,2]
npv_social_lb <- npv_social_stats[31,3]
npv_social_ub <- npv_social_stats[31,4]

ggplot(npv_social, aes(x = npv_social[,1])) +
  geom_histogram(binwidth = 20000, fill = "darkgrey", color = "black", alpha = 0.7) +
  geom_vline(aes(xintercept = npv_social_median), color = "red", linetype = "dashed", size = 1) +  # median line
  geom_vline(aes(xintercept = npv_social_lb), color = "green", linetype = "dotted", size = 1) +  # lower bound
  geom_vline(aes(xintercept = npv_social_ub), color = "green", linetype = "dotted", size = 1) +  # upper bound
  labs(title = "Histogram of Social NPV, with median and 25-75% percentiles", x = "npv", y = "Frequency") +
  scale_x_continuous(breaks = seq(-1000000, 1000000, by = 100000), labels = scales::comma) # need to adjust scales manually

# Overlayed NPV Histograms
set.seed(123)
npv1 <- npv_econ[,1]
npv2 <- npv_social[,1]

# Combine the two datasets into a single data frame
npvplotdf <- data.frame(
  value = c(npv1, npv2),
  Dataset = rep(c("Economic LCCA", "Social LCCA"), each = 1000)
)

# Plot two histograms on top of each other
ggplot(npvplotdf, aes(x = value, fill = Dataset)) +
  geom_histogram(alpha = 0.5, position = "identity", bins = 30) +
  geom_vline(aes(xintercept = npv_econ_median), color = "darkblue", linetype = "dashed", size = 1) +  # median line
  geom_vline(aes(xintercept = npv_social_median), color = "darkgreen", linetype = "dashed", size = 1) +  # lower bound
  scale_fill_manual(values = c("darkblue", "darkgreen")) +  # Custom colors for the two datasets
  labs(title = "Overlayed NPV Histograms with Median on Dashed Line", x = "NPV", y = "Frequency") +
  scale_x_continuous(breaks = seq(-1000000, 1000000, by = 200000), labels = scales::comma) # need to adjust scales manually

```

Plot: NPV Based on discount rate
```{r, eval = FALSE}
# Economic NPV
# Convert years to numeric for plotting
npv_econ_medians$year <- years

# Convert discount rate to numeric for plotting
npv_econ_medians$year <- as.numeric(npv_econ_medians$year)

# plot
ggplot(npv_econ_medians, aes(x = year, y = dr3)) +
  geom_line(color = "darkblue", size = 1) +                      # Line for the mean
  geom_ribbon(aes(ymin = dr0, ymax = dr7), fill = "darkblue", alpha = 0.2) +  # Shaded confidence interval
  labs(title = "NPV at a 3% Discount rate, with 0% - 7% discount rate shaded",
       x = "Year",
       y = "USD") +
  scale_y_continuous(breaks = seq(-1000000, 1000000, by = 200000),labels = comma) + # Format y-axis with commas
  theme_minimal()

# Scoial NPV
# Convert years to numeric for plotting
npv_social_medians$year <- years

# Convert discount rate to numeric for plotting
npv_social_medians$year <- as.numeric(npv_social_medians$year)

# plot
ggplot(npv_social_medians, aes(x = year, y = dr3)) +
  geom_line(color = "darkgreen", size = 1) +                      # Line for the mean
  geom_ribbon(aes(ymin = dr0, ymax = dr7), fill = "darkgreen", alpha = 0.2) +  # Shaded confidence interval
  labs(title = "NPV at a 3% Discount rate, with 0% - 7% discount rate shaded",
       x = "Year",
       y = "USD") +
  scale_y_continuous(breaks = seq(-1000000, 1000000, by = 200000),labels = comma) + # Format y-axis with commas
  theme_minimal()

# Overlayed Line Plot
# New datasets for Overlay
econnpv_overlay <- npv_econ_medians
socialnpv_overlay <- npv_social_medians

# Add group name
econnpv_overlay$group <- "Economic NPV"
socialnpv_overlay$group <- "Social NPV"

# Combine datasets
npv_overlayline_data <- rbind(econnpv_overlay, socialnpv_overlay)

# Create the plot
ggplot(npv_overlayline_data, aes(x = year, y = dr3, group = group)) +
  geom_ribbon(aes(ymin = dr2, ymax = dr4, fill = group), alpha = 0.2) +
  geom_line(aes(color = group), size = 1) +
  scale_fill_manual(values = c("Economic NPV" = "darkblue", "Social NPV" = "darkgreen")) +
  scale_color_manual(values = c("Economic NPV" = "darkblue", "Social NPV" = "darkgreen")) +
  theme_minimal() +
  scale_y_continuous(breaks = seq(-1000000, 1000000, by = 200000),labels = comma) + # Format y-axis with commas
  labs(title = "NPV at a 3% Discount rate, with 2% - 4% discount rate shaded",
       x = "Year",
       y = "USD",
       fill = "npv_overlayline_data",
       color = "npv_overlayline_data")

```

Plot: LCCA Histograms
```{r}
# Histogram of Economic NPV with 3% discount rate
lcca_econ <- as.data.frame(lcca_econ_dr[,30])
lcca_econ_median <- lcca_econ_stats[31,2]
lcca_econ_lb <- lcca_econ_stats[31,3]
lcca_econ_ub <- lcca_econ_stats[31,4]

ggplot(lcca_econ, aes(x = lcca_econ[,1])) +
  geom_histogram(binwidth = 20, fill = "blue", color = "black", alpha = 0.7) +
  geom_vline(aes(xintercept = lcca_econ_median), color = "red", linetype = "dashed", size = 1) +  # median line
  geom_vline(aes(xintercept = lcca_econ_lb), color = "green", linetype = "dotted", size = 1) +  # lower bound
  geom_vline(aes(xintercept = lcca_econ_ub), color = "green", linetype = "dotted", size = 1) +  # upper bound
  labs(title = "Histogram of Economic lcca, with median and 25-75% percentiles", x = "lcca", y = "Frequency") +
  scale_x_continuous(breaks = seq(-500, 500, by = 50), labels = scales::comma) # need to adjust scales manually

# Histogram of Social lcca with 3% discount rate
lcca_social <- as.data.frame(lcca_social_dr[,30])
lcca_social_median <- lcca_social_stats[31,2]
lcca_social_lb <- lcca_social_stats[31,3]
lcca_social_ub <- lcca_social_stats[31,4]

ggplot(lcca_social, aes(x = lcca_social[,1])) +
  geom_histogram(binwidth = 20, fill = "blue", color = "black", alpha = 0.7) +
  geom_vline(aes(xintercept = lcca_social_median), color = "red", linetype = "dashed", size = 1) +  # median line
  geom_vline(aes(xintercept = lcca_social_lb), color = "green", linetype = "dotted", size = 1) +  # lower bound
  geom_vline(aes(xintercept = lcca_social_ub), color = "green", linetype = "dotted", size = 1) +  # upper bound
  labs(title = "Histogram of Social lcca, with median and 25-75% percentiles", x = "lcca", y = "Frequency") +
  scale_x_continuous(breaks = seq(-500, 500, by = 50), labels = scales::comma) # need to adjust scales manually

# Overlayed lcca Histograms
set.seed(123)
lcca1 <- lcca_econ[,1]
lcca2 <- lcca_social[,1]

# Combine the two datasets into a single data frame
lccaplotdf <- data.frame(
  value = c(lcca1, lcca2),
  Dataset = rep(c("Economic LCCA", "Social LCCA"), each = 1000)
)

# Plot two histograms on top of each other
ggplot(lccaplotdf, aes(x = value, fill = Dataset)) +
  geom_histogram(alpha = 0.5, position = "identity", bins = 30) +
  geom_vline(aes(xintercept = lcca_econ_median), color = "darkblue", linetype = "dashed", size = 1) +  # median line
  geom_vline(aes(xintercept = lcca_social_median), color = "darkgreen", linetype = "dashed", size = 1) +  # lower bound
  scale_fill_manual(values = c("darkblue", "darkgreen")) +  # Custom colors for the two datasets
  labs(title = "Overlayed LCCA Histograms with Median on Dashed Line", x = "Value", y = "Frequency") +
  scale_x_continuous(breaks = seq(-500, 500, by = 100), labels = scales::comma) # need to adjust scales manually

```

Plot: LCCA Based on discount rate
```{r, eval = FALSE}
# Economic LCCA
# Convert discount rate to numeric for plotting
lcca_econ_stats$DR <- as.numeric(lcca_econ_stats$DR)

# Filter the confidence results to get rid of any years with zero lcca
plot2_data <- subset(lcca_econ_stats, Median != 0)

# plot
ggplot(plot2_data, aes(x = DR, y = Median)) +
  geom_line(color = "darkblue", size = 1) +                      # Line for the mean
  geom_ribbon(aes(ymin = Lower, ymax = Upper), fill = "darkblue", alpha = 0.2) +  # Shaded confidence interval
  labs(title = "Median, with 25-75% percentile range shaded",
       x = "Discount Rate",
       y = "LCCA") +
  theme_minimal()

# Scoial LCCA
# Convert discount rate to numeric for plotting
lcca_social_stats$DR <- as.numeric(lcca_social_stats$DR)

# Filter the confidence results to get rid of any years with zero lcca
plot3_data <- subset(lcca_econ_stats, Median != 0)

# plot
ggplot(plot3_data, aes(x = DR, y = Median)) +
  geom_line(color = "darkgreen", size = 1) +                      # Line for the mean
  geom_ribbon(aes(ymin = Lower, ymax = Upper), fill = "darkgreen", alpha = 0.2) +  # Shaded confidence interval
  labs(title = "Median, with 25-75% percentile range shaded",
       x = "Discount Rate",
       y = "LCCA") +
  theme_minimal()

# Overlayed Line Plot
# Convert discount rate to numeric for plotting
lcca_econ_stats$DR <- as.numeric(lcca_econ_stats$DR)
lcca_social_stats$DR <- as.numeric(lcca_social_stats$DR)

# Filter the confidence results to get rid of any years with zero lcca
econlcca_linedata <- subset(lcca_econ_stats, Median != 0)
sociallcca_line_data <- subset(lcca_social_stats, Median != 0)

# Add group name
econlcca_linedata$group <- "Economic LCCA"
sociallcca_line_data$group <- "Social LCCA"

# Combine datasets
overlayline_data <- rbind(econlcca_linedata, sociallcca_line_data)

# Create the plot
ggplot(overlayline_data, aes(x = DR, y = Median, group = group)) +
  geom_ribbon(aes(ymin = Lower, ymax = Upper, fill = group), alpha = 0.2) +
  geom_line(aes(color = group), size = 1) +
  scale_fill_manual(values = c("Economic LCCA" = "darkblue", "Social LCCA" = "darkgreen")) +
  scale_color_manual(values = c("Economic LCCA" = "darkblue", "Social LCCA" = "darkgreen")) +
  theme_minimal() +
  labs(title = "Median LCCA, with 25-75% percentile range shaded",
       x = "Discount Rate",
       y = "LCCA",
       fill = "overlayline_data",
       color = "overlayline_data")

```